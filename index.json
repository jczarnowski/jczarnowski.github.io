[{"authors":null,"categories":null,"content":"Hi! My name is Jan Czarnowski, I am a PhD Student at Imperial College London under the supervision of Andrew Davison. Prior to that I led a team of robotics researchers in PIAP, Warsaw. My research focuses on integrating Deep Learning with Dense Visual SLAM in order to push the boundaries of spatial perception with a single camera. I enjoy building systems that work in real-time and produce good-looking 3D visualisations and probably spend too much time on computer games.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"/author/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/admin/","section":"author","summary":"Hi! My name is Jan Czarnowski, I am a PhD Student at Imperial College London under the supervision of Andrew Davison. Prior to that I led a team of robotics researchers in PIAP, Warsaw. My research focuses on integrating Deep Learning with Dense Visual SLAM in order to push the boundaries of spatial perception with a single camera. I enjoy building systems that work in real-time and produce good-looking 3D visualisations and probably spend too much time on computer games.","tags":null,"title":"","type":"author"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"d41d8cd98f00b204e9800998ecf8427e","permalink":"/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"author","summary":"","tags":null,"title":"Authors","type":"author"},{"authors":["Michael Bloesch","Jan Czarnowski","Ronald Clark","Stefan Leutenegger","Andrew J. Davison"],"categories":null,"content":"","date":1522738800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522738800,"objectID":"727288535170abe53e81cfa6c98df3ef","permalink":"/publication/code-slam/","publishdate":"2018-04-03T00:00:00-07:00","relpermalink":"/publication/code-slam/","section":"publication","summary":"The representation of geometry in real-time 3D perception systems continues to be a critical research issue. Dense maps capture complete surface shape and can be augmented with semantic labels, but their high dimensionality makes them computationally costly to store and process, and unsuitable for rigorous probabilistic inference. Sparse feature-based representations avoid these problems, but capture only partial scene information and are mainly useful for localisation only.We present a new compact but dense representation of scene geometry which is conditioned on the intensity data from a single image and generated from a code consisting of a small number of parameters. We are inspired by work both on learned depth from images, and auto-encoders. Our approach is suitable for use in a keyframe-based monocular dense SLAM system: While each keyframe with a code can produce a depth map, the code can be optimised efficiently jointly with pose variables and together with the codes of overlapping keyframes to attain global consistency. Conditioning the depth map on the image allows the code to only represent aspects of the local geometry which cannot directly be predicted from the image. We explain how to learn our code representation, and demonstrate its advantageous properties in monocular SLAM.","tags":[],"title":"CodeSLAM - Learning a Compact, Optimisable Representation for Dense Visual SLAM","type":"publication"},{"authors":["Jan Czarnowski","Stefan Leutenegger","Andrew J. Davison"],"categories":null,"content":"","date":1501570800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501570800,"objectID":"a4baddfb31284afe402a1d6aeca3f7e2","permalink":"/publication/sem-tex/","publishdate":"2017-08-01T00:00:00-07:00","relpermalink":"/publication/sem-tex/","section":"publication","summary":"We  argue  that  robust  dense  SLAM  systems  can  makevaluable use of the layers of features coming from a stan-dard CNN as a pyramid of ‘semantic texture’ which is suit-able for dense alignment while being much more robust tonuisance factors such as lighting than raw RGB values. Weuse a straightforward Lucas-Kanade formulation of imagealignment, with a schedule of iterations over the coarse-to-fine levels of a pyramid, and simply replace the usual im-age pyramid by the hierarchy of convolutional feature mapsfrom a pre-trained CNN. The resulting dense alignment per-formance is much more robust to lighting and other varia-tions, as we show by camera rotation tracking experimentson time-lapse sequences captured over many hours.  Look-ing towards the future of scene representation for real-timevisual SLAM, we further demonstrate that a selection usingsimple criteria of a small number of the total set of featuresoutput by a CNN gives just as accurate but much more effi-cient tracking performance.","tags":[],"title":"Semantic Texture for Robust Dense Tracking","type":"publication"},{"authors":["Ronald Clark","Michael Bloesch","Jan Czarnowski","Stefan Leutenegger","Andrew J. Davison"],"categories":null,"content":"","date":1473404400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473404400,"objectID":"21ad27d745ecd9dc0900d3bae8637900","permalink":"/publication/ls-net/","publishdate":"2016-09-09T00:00:00-07:00","relpermalink":"/publication/ls-net/","section":"publication","summary":"Sum-of-squares objective functions are very popular in computer vision algorithms. However, these objective functions are not always easy to optimize. The underlying assumptions made by solvers are often not satisfied and many problems are inherently ill-posed. In this paper, we propose LS-Net, a neural nonlinear least squares optimization algorithm which learns to effectively optimize these cost functions even in the presence of adversities. Unlike traditional approaches, the proposed solver requires no hand-crafted regularizers or priors as these are implicitly learned from the data. We apply our method to the problem of motion stereo ie. jointly estimating the motion and scene geometry from pairs of images of a monocular sequence. We show that our learned optimizer is able to efficiently and effectively solve this challenging optimization problem.","tags":[],"title":"LS-Net: Learning to Solve Nonlinear Least Squares for Monocular Stereo","type":"publication"},{"authors":["Admin"],"categories":null,"content":"test content\n","date":1461135600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515830400,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"/post/getting-started/","publishdate":"2016-04-20T00:00:00-07:00","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website or blog in under 10 minutes.","tags":["Academic"],"title":"Test post","type":"post"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]